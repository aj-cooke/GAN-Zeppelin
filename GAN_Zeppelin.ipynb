{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Zeppelin\n",
    "### This project uses a Generative Adversarial Network to generate new five second chunks of Led Zeppelin songs.\n",
    "The Discriminator was trained on Led Zeppelin's entire discography split into five second chunks. Unfortunately, I cannot include the data here, but this can be done if you have the music already or with any other collection of songs.\n",
    "\n",
    "Like many GANs, this project is meant to be fun and experimental. Most GANs that are able to make faithful recreations of what they are trying to generate do so on datasets with a large amount of samples and a relatively low complexity (tens of thousand of samples of 96x96 images). This dataset includes much more complicated data (One second of high-res sound data is a one dimensional array of 22,050 values, each of which is a very long float). To maximize effectiveness, the songs were split into smaller chunks, increasing the number of samples and decreasing the data complexity. This still falls very short of what would likely result in high quality generations, but it should be an insightful experiment and the code can be used to create GANs for other sound data projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some resources I used to help create this project were as follows:\n",
    "Keras implementation example: https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "jeffheaton GAN tutorial on GitHub: https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_Keras_gan.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import LeakyReLU, Conv1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "import librosa\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This try-catch block checks if the processed sound data exists\n",
    "#If not, it finds a folder full of .wav files of Led Zeppelin songs, unpacks the wavs into arrays, and splits the songs into chunks\n",
    "\n",
    "try:  \n",
    "    dest_file = 'Zeppelin_Chunks.csv'\n",
    "    with open(dest_file, newline='') as dest_f:\n",
    "        reader = csv.reader(dest_f)\n",
    "        data = [data for data in reader]\n",
    "    X_train = np.asarray(data, dtype = float)\n",
    "\n",
    "except:\n",
    "    print(\"F\")\n",
    "    X_train_dir = 'C:/Users/Andy/Led_Zeppelin_WAV/'\n",
    "    X_train = []\n",
    "    \n",
    "    clip_length = 22050*5\n",
    "    \n",
    "    def chunks(lst, n, dest):\n",
    "        \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "        for i in range(0, len(lst), n):\n",
    "            dest.append(list(lst[i:i + n]))     \n",
    "     \n",
    "    for song in os.listdir(X_train_dir):\n",
    "        songname = f'{X_train_dir}{song}'\n",
    "        sample, sr = librosa.load(songname, mono=True, duration=360)\n",
    "        chunks(sample,clip_length,X_train)\n",
    "    \n",
    "    x = 0\n",
    "    for i in X_train:\n",
    "        num_zeros = i.count(0)\n",
    "        pzeros = num_zeros/clip_length\n",
    "        if len(i) != clip_length or pzeros >= 0.25:\n",
    "            del X_train[x]\n",
    "        x += 1\n",
    "        \n",
    "    X_train = np.array(X_train)\n",
    "    np.savetxt('Zeppelin_Chunks.csv', X_train, delimiter=',', fmt='%d')\n",
    "\n",
    "np.random.shuffle(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_SIZE = 100 #This will affect how the generator behaves\n",
    "\n",
    "DATA_PATH = 'C:/Users/Andy/Documents/'\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple function to print time during training\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Generator\n",
    "\n",
    "def build_generator(seed_size): #Accepts the seed as an input\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(2*2*128,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((1,512)))\n",
    "\n",
    "    model.add(Conv1D(256,kernel_size = 3, padding = 'same')) #Conv1D is used beause sound data is a 1D array\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Conv1D(128,kernel_size = 3, padding = 'same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(X_train[0].shape[0]))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Discriminator\n",
    "\n",
    "def build_discriminator(clip_length): #Accepts actual chunks of Zeppelin Songs and generated samples\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(32, activation='relu', input_dim=((clip_length))))\n",
    "    model.add(Reshape((1,32)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1, 256)            393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 128)            98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 110250)            14222250  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 110250)            0         \n",
      "=================================================================\n",
      "Total params: 14,767,402\n",
      "Trainable params: 14,766,634\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build generator and check the summary to see if it looks right\n",
    "generator = build_generator(SEED_SIZE)\n",
    "\n",
    "generator.summary()\n",
    "\n",
    "noise = tf.random.normal([1, SEED_SIZE])\n",
    "\n",
    "generated_clip = generator(noise, training=False)\n",
    "\n",
    "clip_length = X_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                3528032   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 64)             6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,534,561\n",
      "Trainable params: 3,534,433\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build Discriminator\n",
    "discriminator = build_discriminator(clip_length)\n",
    "\n",
    "discriminator.summary()\n",
    "\n",
    "decision = discriminator(generated_clip)\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The loss functions and optimizers for the generator and discriminator must be defined seperately\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are the training and train step functions taken from the TensorFlow tutorials website. Learn more at the link provided.\n",
    "@tf.function\n",
    "def train_step(clips):\n",
    "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(seed, training=True)\n",
    "\n",
    "    real_output = discriminator(tf.reshape(clips,(1,clip_length)), training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "  return gen_loss,disc_loss\n",
    "\n",
    "def train(dataset, epochs):\n",
    "  start = time.time()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    gen_loss_list = []\n",
    "    disc_loss_list = []\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      t = train_step(image_batch)\n",
    "      gen_loss_list.append(t[0])\n",
    "      disc_loss_list.append(t[1])\n",
    "\n",
    "    g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "    d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "    epoch_elapsed = time.time()-epoch_start\n",
    "    epoch_elapsed = hms_string(epoch_elapsed)\n",
    "    print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'\\\n",
    "           f'{epoch_elapsed}')\n",
    "\n",
    "  elapsed = time.time()-start\n",
    "  print (f'Training time: {hms_string(elapsed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now it is time to train the model, save it and create some samples\n",
    "train(X_train, EPOCHS)\n",
    "\n",
    "generator.save(os.path.join(DATA_PATH,\"lz_generator.h5\"))\n",
    "\n",
    "example_output = generator.predict(tf.random.normal([1, SEED_SIZE]))\n",
    "example_output = example_output.reshape(example_output.shape[1],1)\n",
    "srate = 22050\n",
    "librosa.output.write_wav(os.path.join(DATA_PATH,'lz_gen.wav'), example_output, srate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have included some results in the GitHub repository. They are very staticky, but if you turn up your speakers, you can hear guitar notes and some ethereal vocal \"whoah\" sounds. To make a successful GAN on sound data, one would need far more samples and more similar samples, but this code can be used to build other GAN's or classifiers on sound data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
